<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Object Tracking for Ball Trajectory</title>
    
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha3/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="styles.css"> <!-- Your custom CSS -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
</head>
<body>
    <header>
        <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
            <div class="container-fluid">
                <a class="navbar-brand" href="#">Basketball Shot Analysis</a>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>
                <div class="collapse navbar-collapse" id="navbarNav">
                    <ul class="navbar-nav ms-auto"> <!-- Right aligned navbar -->
                        <li class="nav-item">
                            <a class="nav-link" href="index.html">Home</a>
                        </li>
                        
                        <li class="nav-item">
                            <a class="nav-link" href="object_detection.html">Object Detection</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="object_tracking.html">Object Tracking</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="motion_analysis.html">Motion Analysis</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="challenges.html">Challenges</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="future_directions.html">Future Directions</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="bibilography.html">Bibilography</a>
                        </li>
                    </ul>
                </div>
            </div>
        </nav>
    </header>
    <div class="button-container">
        <a class="btn btn-outline-primary" onclick="speakText()" style="margin-right: 10px;">Listen</a>
        <a class="btn btn-outline-secondary" onclick="stopSpeaking()">Stop</a>
    </div>
    <section id="object-tracking" class="container mt-5">
        <div id="textToSpeak">
        <h2>Object Tracking for Ball Trajectory</h2>
        <hr style="border: 4px solid #000; width: 100%; margin: auto;">
        <br>
        <h3>Object Tracking</h3>
        <p>Object tracking is a crucial technique in computer vision that focuses on following specific objects as they move through a sequence of video frames. While object detection identifies and locates objects in a single image, tracking takes it a step further by maintaining the identity of these objects over time. This means that once an object is detected, the tracking system continues to monitor its position and movement, even as it changes location or orientation. Object tracking can be applied in various fields, such as video surveillance, where it helps monitor people or vehicles for security purposes, and in sports, where it analyzes player movements for performance improvement. The process involves algorithms that can handle challenges like occlusion, where objects might temporarily disappear from view, and variations in lighting conditions. Overall, object tracking is essential for creating intelligent systems that understand dynamic environments, making it a fundamental aspect of advanced video analysis and real-time applications.</p>
        <div class="object_image_container">
            <img src="assets\object_tracking\tracking.jpeg" alt="object_tracking_image" class="img-thumbnail" id="object_detetc_box">
            <img src="assets\object_tracking\tracking_gif.gif" alt="object_tracking_gif" class="img-thumbnail" id="object_detetc_box">
        </div>

        <h3>Implementation in Basketball Shot Analysis</h3>
        <p>Object tracking is important in basketball ballistic analysis because it helps to follow the movement of the basketball during games. By using cameras placed around the court, analysts can capture videos that show how the ball travels through the air. This information is valuable because it reveals details like how high the ball is released, how fast it moves, and at what angles it is shot. Coaches and players can use this data to understand the best ways to make successful shots. For example, they can learn which angles and speeds lead to better scoring chances, allowing them to practice specific skills to improve their game. By studying how the ball interacts with the hoop, teams can discover patterns that help them play better. Overall, object tracking gives valuable insights into the ball's movement, helping players become more effective on the court. Research such as that by Yan, Jiang, and Liu (2023) provides a comprehensive review of basketball shooting analysis using AI, underscoring the importance of tracking for deeper insights . Further, Kadam et al. (2023) show how techniques like polynomial regression are applied in basketball shot prediction, which may benefit from advanced object tracking . The work by Kao et al. (2022) also illustrates how hoop-centric trajectory analysis can aid in precise shot tracking .</p>
        <div style="display:flex;justify-content: center;">
        <img src="assets\object_tracking\basket_tracking.gif" alt="object_tracking_image" class="img-thumbnail" id="object_detetc_box">
        </div>
        <br>
        <h3>Key Algorithms in Object Tracking</h1>
        <ul>
            <li style="margin: 20px 0; list-style-type: none;">
                <strong>Kalman Filter:</strong> 
                The Kalman Filter is a highly effective algorithm widely used for tracking the position and movement of objects over time. It works by following a two-step process: prediction and update. In the prediction phase, the filter estimates where the object will be based on its last known position and a specific motion model, like constant speed. This step not only predicts the objectâ€™s location but also considers how certain we are about that prediction, represented as error covariance. When a new measurement, such as the object's location detected by a camera, becomes available, the Kalman Filter enters the update phase. Here, it combines the predicted position with the actual measurement to refine its estimates, reducing errors and recalibrating uncertainty. This blend of prediction and measurement helps to smooth out any noisy data, leading to more accurate tracking results. The strength of the Kalman Filter lies in its ability to provide consistent and stable estimates, even in chaotic environments where data can be unreliable. This makes it a vital tool in various fields, including robotics, aerospace, and automotive applications, where precise tracking of moving objects, such as drones or vehicles, is crucial for successful operation.
            </li>
            <li style="margin: 20px 0; list-style-type: none;">
                <strong>Optical Flow:</strong>
                Optical Flow is an established technique in computer vision that helps in estimating how objects are moving by analyzing changes in pixel brightness between consecutive video frames. The basic idea behind Optical Flow is that by observing how the brightness of pixels shifts over time, we can infer the motion of objects within the scene. To achieve this, the algorithm calculates the speed and direction of movement for each pixel, resulting in a flow field that visually represents motion throughout the image. There are popular methods for calculating Optical Flow, such as the Lucas-Kanade method, which looks at small groups of neighboring pixels to estimate motion, and the Horn-Schunck method, which considers smoothness across the entire image to produce a cohesive flow representation. One of the main benefits of Optical Flow is its efficiency in tracking slight movements and changes in scenes where lighting conditions are steady. Because of these capabilities, Optical Flow is particularly useful in applications like video surveillance, where it can monitor people or vehicles; gesture recognition, where it interprets human movements; and vehicle tracking, where it aids in understanding the dynamics of traffic. By providing insights into how objects move, Optical Flow plays a critical role in enhancing our understanding of motion in various contexts.
            </li>
            <li style="margin: 20px 0; list-style-type: none;">
                <strong>Deep SORT:</strong>
                Deep SORT, which stands for Deep Simple Online and Real-time Tracking, is an advanced algorithm that improves upon the original SORT method by integrating deep learning techniques for enhanced object tracking. It is especially effective in challenging environments with multiple objects moving simultaneously. Like the original SORT, Deep SORT uses a Kalman Filter to predict where objects will be over time. However, it goes further by employing sophisticated data association methods to keep track of these objects as they move. Using the Hungarian algorithm, Deep SORT matches detected objects from one frame to the next based on their predicted positions. What truly distinguishes Deep SORT is its incorporation of deep learning to extract appearance features from images, typically using a convolutional neural network (CNN). This deep learning aspect allows the algorithm to recognize and differentiate between various objects, even when they overlap or are partially hidden from view. The combination of these techniques results in a powerful tracking solution that not only maintains the identities of multiple objects but also adapts well to real-time demands. This makes Deep SORT highly valuable in fields like video surveillance, sports analysis, and autonomous driving, where understanding the movement and identity of each object is crucial for safety and operational success.
            </li>
        </ul>
        <h3>Comparative List of Object Tracking Algorithms</h3>

            <ul>
                <li style="margin: 20px 0; list-style-type: none;">
                    <strong>Kalman Filter</strong>
                    <p>
                        The Kalman Filter is a recursive algorithm designed for estimating the state of a moving object over time. One of its key advantages is its ability to provide smooth and stable estimates, even in noisy environments, making it particularly effective for tracking tasks with predictable motion, such as vehicles. However, it does have limitations; it assumes linearity and Gaussian noise, which can lead to struggles when faced with abrupt changes in motion. Therefore, the Kalman Filter is best suited for scenarios where the object's movement is relatively predictable and straightforward.
                    </p>
                </li>
                
                <li style="margin: 20px 0; list-style-type: none;">
                    <strong>Optical Flow</strong>
                    <p>
                        Optical Flow estimates motion by analyzing changes in pixel intensity between consecutive frames. This method works well for small, consistent movements and is efficient for real-time applications, making it suitable for video surveillance and gesture recognition. However, it is sensitive to lighting changes and may not perform effectively when objects are occluded. Consequently, Optical Flow is most effective in environments with consistent lighting and smooth motion.
                    </p>
                </li>
                
                <li style="margin: 20px 0; list-style-type: none;">
                    <strong>Deep SORT</strong>
                    <p>
                        Deep SORT enhances traditional tracking by combining a Kalman Filter with deep learning techniques, allowing it to maintain the identity of objects in complex environments. Its advantages include high accuracy and robustness, particularly in scenarios with multiple overlapping objects, such as sports analysis. However, Deep SORT is computationally intensive and requires a trained deep learning model, which can limit its usability in resource-constrained settings. Therefore, it is best applied in real-time applications where the maintenance of object identity is critical.
                    </p>
                </li>
            </ul>

        <h3>When to Use Each Algorithm</h3>

            <ul>
                <li style="margin: 20px 0; list-style-type: none;">
                    <strong>Kalman Filter</strong>
                    <p>
                        Ideal for scenarios where the motion of the object is predictable, such as tracking vehicles. It is best suited for linear motion and Gaussian noise scenarios.
                    </p>
                </li>
                
                <li style="margin: 20px 0; list-style-type: none;">
                    <strong>Optical Flow</strong>
                    <p>
                        Effective for small, consistent movements, making it suitable for monitoring people. It works best in consistent lighting with smooth motion.
                    </p>
                </li>
                
                <li style="margin: 20px 0; list-style-type: none;">
                    <strong>Deep SORT</strong>
                    <p>
                        Suitable for tracking multiple objects in crowded environments. It requires access to a trained deep learning model and adequate computational resources.
                    </p>
                </li>
            </ul>

        <h4>Key takeaways</h4>
            <p>
                For straightforward motion, use <b>Kalman Filter</b>; for small motions, <b>Optical Flow</b> is ideal; for complex scenarios, <b>Deep SORT</b> offers robust capabilities. Understanding the strengths and limitations of each method allows for selecting the most suitable algorithm for object tracking needs.
            </p>


        <div class="navigation-buttons" style="display: flex; justify-content: flex-end;">
                <a href="motion_analysis.html" style="margin-right: 30px;">
                     <i class="fas fa-arrow-right fa-3x"></i>
                </a>
        </div> 
        <br><br>
    </div>   
    </section>

    <footer>
        <p>&copy; 2024 Basketball Shot Analysis</p>
    </footer>

    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha3/dist/js/bootstrap.bundle.min.js"></script>
    <script>
        function speakText() {
            const text = document.getElementById("textToSpeak").innerText; // Get text from a specific element
            const speech = new SpeechSynthesisUtterance(text);
            speech.lang = 'en-US'; // Set the language
            window.speechSynthesis.speak(speech);
        }
        function stopSpeaking() {
            window.speechSynthesis.cancel(); // Stop any ongoing speech
        }
        window.onbeforeunload = function () {
        stopSpeaking();
    };
    </script>
</body>
</html>
